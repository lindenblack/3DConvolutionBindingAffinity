{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "model_code_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZIZYU8sT11R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b4a63b-e16a-4a53-e4dc-49d4d927cb81"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Github/3DQSAR"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Github/3DQSAR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbzLAnR4TqxL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import BatchNormalization,Flatten,\\\n",
        "Add,Input,Dense, Dropout, Activation, InputLayer, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import sklearn\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "# from augmentation_code import data_augmentation\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import os \n",
        "import pickle\n",
        "import scipy\n",
        "import random\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DykRKOZikxEF"
      },
      "source": [
        "def split_shuffle(X_1,X_2,Y,augment,aug_iter):\n",
        "    ###Reshape\n",
        "    X_1,X_2,Y = pickle.load(open(\"/content/drive/My Drive/Github/resized_first_1000_data_full.p\", \"rb\"))\n",
        "    Y=np.asarray(Y)\n",
        "    X_1 = np.reshape(X_1,(X_1.shape[0],X_1.shape[1],X_1.shape[2],X_1.shape[3],1))\n",
        "    X_2 = np.reshape(X_2,(X_2.shape[0],X_2.shape[1],X_2.shape[2],X_2.shape[3],1))\n",
        "    \n",
        "    mol1 = np.where(Y==(5.154902))\n",
        "    mol2 = np.where(Y==(5.815309))\n",
        "    mol3 = np.where(Y==(6.69897))\n",
        "    mol4 = np.where(Y==(7.85))\n",
        "    mol5 = np.where(Y==(8.102373)) \n",
        "\n",
        "    test_index = np.hstack([mol1,mol2,mol3,mol4,mol5])\n",
        "\n",
        "    test_index = np.squeeze(test_index)\n",
        "\n",
        "    X_1_train = np.delete(X_1,test_index,0)\n",
        "    X_2_train = np.delete(X_2,test_index,0)\n",
        "    X_1_test = X_1[test_index]\n",
        "    X_2_test = X_2[test_index]\n",
        "\n",
        "    Y_train = np.delete(Y,test_index)\n",
        "    Y_test = Y[test_index]\n",
        "    del X_1,X_2,Y\n",
        "           \n",
        "    mol1 = np.where(Y_train==(5.19382))\n",
        "    mol2 = np.where(Y_train==(5.497573))\n",
        "    mol3 = np.where(Y_train==(5.699622))\n",
        "    mol4 = np.where(Y_train==(5.9))\n",
        "    mol5 = np.where(Y_train==(6.346787))\n",
        "\n",
        "    mol6 = np.where(Y_train==(6.102373))\n",
        "    mol7 = np.where(Y_train==(6.63))\n",
        "    mol8 = np.where(Y_train==(7.1))\n",
        "    mol9 = np.where(Y_train==(7.9))\n",
        "    mol10 = np.where(Y_train==(8.)) \n",
        "    \n",
        "    val_index = np.hstack([mol1,mol2,mol3,mol4,mol5,\n",
        "                           mol6,mol7,mol8,mol9,mol10])\n",
        "    \n",
        "    val_index = np.squeeze(val_index)\n",
        "\n",
        "    X_1_val = X_1_train[val_index]\n",
        "    X_2_val = X_2_train[val_index]\n",
        "    X_1_train = np.delete(X_1_train, val_index, 0)\n",
        "    X_2_train = np.delete(X_2_train, val_index, 0)\n",
        "\n",
        "    Y_val = Y_train[val_index]\n",
        "    Y_train = np.delete(Y_train, val_index)\n",
        "\n",
        "    #############################\n",
        "    #UNDER SAMPLING\n",
        "    #############################\n",
        "    sort_indexes = np.argsort(Y_train)\n",
        "    X_1_train = X_1_train[sort_indexes]\n",
        "    X_2_train = X_2_train[sort_indexes]\n",
        "    Y_train = Y_train[sort_indexes]\n",
        "    split = np.where(Y_train>=7.28)[0][0]\n",
        "    #############################\n",
        "    #Under sampling param is split/param\n",
        "    #############################\n",
        "    perm_under = np.random.RandomState(42)\\\n",
        "                  .randint(0,split,(int(np.around(split/6,0))))\n",
        "    Y_under = Y_train[perm_under]\n",
        "    X_1_under = X_1_train[perm_under]\n",
        "    X_2_under = X_2_train[perm_under]\n",
        "    Y_train= np.append(Y_under,Y_train[split:],axis=0)\n",
        "    X_1_train= np.append(X_1_under,X_1_train[split:],axis=0)\n",
        "    X_2_train= np.append(X_2_under,X_2_train[split:],axis=0)\n",
        "\n",
        "\n",
        "    permutation_train = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_train.shape[0])\n",
        "    permutation_test = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_test.shape[0])\n",
        "    permutation_val = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_val.shape[0])\n",
        "\n",
        "    split_train = int(np.around(X_1_train.shape[0]/2,0))\n",
        "    split_val = int(np.around(X_1_val.shape[0]/4,0))\n",
        "    split_test = int(np.around(X_1_test.shape[0]/4,0))\n",
        "\n",
        "    X_1_val =   X_1_val[permutation_val]#[:split_val] \n",
        "    X_2_val =   X_2_val[permutation_val]#[:split_val] \n",
        "    X_1_train = X_1_train[permutation_train]#[:split_train]\n",
        "    X_2_train = X_2_train[permutation_train]#[:split_train]\n",
        "    Y_val =     Y_val[permutation_val]#[:split_val]\n",
        "    Y_train =   Y_train[permutation_train]#[:split_train] \n",
        "    X_1_test =  X_1_test[permutation_test]#[:split_test]\n",
        "    X_2_test =  X_2_test[permutation_test]#[:split_test]\n",
        "    Y_test =    Y_test[permutation_test]#[:split_test]\n",
        "\n",
        "    # if augment and aug_iter!=0:\n",
        "    #   indexes = np.where(Y_train>7.25)\n",
        "    #   for _ in np.arange(aug_iter):\n",
        "        \n",
        "    #     new_X = scipy.ndimage.gaussian_filter(X_1_train[indexes],sigma=(1))\n",
        "    #     X_1_train = np.concatenate([X_1_train,new_X])\n",
        "\n",
        "    #     new_X = scipy.ndimage.gaussian_filter(X_2_train[indexes],sigma=(1))\n",
        "    #     X_2_train = np.concatenate([X_2_train,new_X])\n",
        "\n",
        "    #     Y_train = np.concatenate([Y_train,Y_train[indexes]])\n",
        "\n",
        "    #     new_X = scipy.ndimage.rotate(axes=(1,2),X_1_train[indexes],random.choice([90,180,270]),reshape=False,order=4)\n",
        "    #     X_1_train = np.concatenate([X_1_train,new_X])\n",
        "\n",
        "    #     new_X = scipy.ndimage.rotate(axes=(1,2),X_2_train[indexes],random.choice([90,180,270]),reshape=False,order=4)\n",
        "    #     X_2_train = np.concatenate([X_2_train,new_X])\n",
        "\n",
        "    #     Y_train = np.concatenate([Y_train,Y_train[indexes]])\n",
        "    # else:\n",
        "    #   print(\"No augmentation!\")  \n",
        "\n",
        "    return X_1_train, X_1_test, X_1_val, X_2_train, X_2_test, X_2_val, Y_train, Y_test, Y_val"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDAg1E3JTqxa"
      },
      "source": [
        "def build_CNN(X_1_train):\n",
        "    model = Sequential(name='CNN')\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    inputs = Input(shape=(X_1_train.shape[1], X_1_train.shape[2],X_1_train.shape[3],X_1_train.shape[4]))\n",
        "    model=inputs\n",
        "    model = Conv3D(32, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = MaxPooling3D(pool_size=(2,2,2))(model)   \n",
        "    model = Conv3D(64, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
        "    model = Conv3D(128, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    # model = Conv3D(256, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    # model = Conv3D(512, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
        "    model = Flatten()(model)\n",
        "    model = Dense(100,activation='relu')(model)\n",
        "    \n",
        "    output = model\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R76E2eiU-g8Z"
      },
      "source": [
        "def build_deep_CNN(X_1_train):\n",
        "    model = Sequential(name='CNN')\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    inputs = Input(shape=(X_1_train.shape[1], X_1_train.shape[2],X_1_train.shape[3],X_1_train.shape[4]))\n",
        "    model=inputs\n",
        "    model = Conv3D(32, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    # model = MaxPooling3D(pool_size=(2,2,2))(model)   \n",
        "    model = Conv3D(64, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
        "    model = Conv3D(128, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = Conv3D(256, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = Conv3D(512, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
        "    model = Flatten()(model)\n",
        "    model = Dense(100,activation='relu')(model)\n",
        "    \n",
        "    output = model\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxU1ILcJTqxa"
      },
      "source": [
        "def two_headed_network(X_1_train):\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    X_1_CNN = build_CNN(X_1_train)\n",
        "    X_2_CNN = build_CNN(X_1_train)\n",
        "    network = Add()([X_1_CNN.output,X_2_CNN.output])\n",
        "    network = Dense(100,activation='relu')(network)\n",
        "    network = Dense(50,activation='relu')(network)\n",
        "    network = Dense(10,activation='relu')(network)\n",
        "    network = Dense(1,activation = 'linear')(network)\n",
        "    model = Model([X_1_CNN.input, X_2_CNN.input], network)\n",
        "    optimizer = Adam(learning_rate=1e-2)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model  \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdo3DyR_BwAo"
      },
      "source": [
        "def train(CNN,X_1_train, X_1_val, X_2_train,\\\n",
        "  X_2_val, Y_train, Y_val):\n",
        "\n",
        "  monitor = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=30,\n",
        "                          verbose=1, \n",
        "                          mode='auto',\n",
        "                          restore_best_weights=True)\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed(42)\n",
        "  history=CNN.fit([X_1_train, X_2_train],\n",
        "          Y_train,\n",
        "          batch_size=32,\n",
        "          epochs=1000, \n",
        "          validation_data=([X_1_val, X_2_val],\n",
        "                            Y_val),\n",
        "                            callbacks=[monitor],\n",
        "          shuffle=True,\n",
        "          verbose=1)\n",
        "  \n",
        "  model_loss = CNN.evaluate([X_1_val,X_2_val], Y_val, verbose=0)\n",
        "  return model_loss,CNN,history"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLBgFURvQPzo"
      },
      "source": [
        "def run(itr):\n",
        "  X_1,X_2,Y = pickle.load(open(\"/content/drive/My Drive/Github/resized_first_1000_data_full.p\", \"rb\"))\n",
        "  Y = np.asarray(Y)\n",
        "  X_1_train, X_1_test, X_1_val, X_2_train, X_2_test,\\\n",
        "  X_2_val, Y_train, Y_test, Y_val = split_shuffle(X_1,X_2,Y,augment=True,aug_iter=itr)\n",
        "  del X_1,X_2,Y\n",
        "  \n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed(42)\n",
        "\n",
        "  CNN = two_headed_network(X_1_train)\n",
        "  loss,CNN,history = train(CNN,X_1_train, X_1_val, X_2_train,\\\n",
        "                 X_2_val, Y_train, Y_val)\n",
        "  print(loss)\n",
        "  plt.hist(Y_train)\n",
        "  return loss,CNN,history"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1nkIs8G_NFw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "9ab75eb5-60a0-4a68-9f7b-ff127a60581f"
      },
      "source": [
        "##################Run experiment\n",
        "loss,CNN,history = run(0)\n",
        "tf.keras.backend.clear_session()\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "162/350 [============>.................] - ETA: 2:14 - loss: 4071375.7500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-05ad4d3ec216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##################Run experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-874c0cee2de5>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_headed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2_train\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mX_2_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-fc3f9b4bafe7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(CNN, X_1_train, X_1_val, X_2_train, X_2_val, Y_train, Y_val)\u001b[0m\n\u001b[1;32m     17\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           verbose=1)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mmodel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_1_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_2_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}