{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_code_colab_categorical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZIZYU8sT11R",
        "outputId": "74b0167e-e225-49fb-92a9-7e09e06fc893"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Github/3DQSAR"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Github/3DQSAR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO1PbjDlUNuH"
      },
      "source": [
        "# !pip install --upgrade batchgenerators"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbzLAnR4TqxL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import BatchNormalization,Flatten,\\\n",
        "Add,Input,Dense, Dropout, Activation, InputLayer, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import os \n",
        "import pickle\n",
        "import scipy\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3_gGwRLBp8K"
      },
      "source": [
        "def categorical_label(Y):\n",
        "  Y_cat=np.zeros(Y.shape[0])\n",
        "  for idx in range(len(Y)):\n",
        "    if Y[idx] >=6:\n",
        "      Y_cat[idx]=1\n",
        "    else:\n",
        "      Y_cat[idx]=0\n",
        "  return Y_cat"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DykRKOZikxEF"
      },
      "source": [
        "def split_shuffle(X_1,X_2,Y,augment,aug_iter):\n",
        "    ###Reshape\n",
        "    Y=np.asarray(Y)\n",
        "    \n",
        "    X_1 = np.reshape(X_1,(X_1.shape[0],X_1.shape[1],X_1.shape[2],X_1.shape[3],1))\n",
        "    X_2 = np.reshape(X_2,(X_2.shape[0],X_2.shape[1],X_2.shape[2],X_2.shape[3],1))\n",
        "    \n",
        "    mol1 = np.where(Y==(5.154902))\n",
        "    mol2 = np.where(Y==(5.815309))\n",
        "    mol3 = np.where(Y==(6.69897))\n",
        "    mol4 = np.where(Y==(7.85))\n",
        "    mol5 = np.where(Y==(8.102373)) \n",
        "\n",
        "    test_index = np.hstack([mol1,mol2,mol3,mol4,mol5])\n",
        "\n",
        "    test_index = np.squeeze(test_index)\n",
        "\n",
        "    X_1_train = np.delete(X_1,test_index,0)\n",
        "    X_2_train = np.delete(X_2,test_index,0)\n",
        "    X_1_test = X_1[test_index]\n",
        "    X_2_test = X_2[test_index]\n",
        "\n",
        "    Y_train = np.delete(Y,test_index)\n",
        "    Y_test = Y[test_index]\n",
        "    del X_1,X_2,Y\n",
        "           \n",
        "    mol1 = np.where(Y_train==(5.19382))\n",
        "    mol2 = np.where(Y_train==(5.497573))\n",
        "    mol3 = np.where(Y_train==(5.699622))\n",
        "    mol4 = np.where(Y_train==(5.9))\n",
        "    mol5 = np.where(Y_train==(6.346787))\n",
        "\n",
        "    mol6 = np.where(Y_train==(6.102373))\n",
        "    mol7 = np.where(Y_train==(6.63))\n",
        "    mol8 = np.where(Y_train==(7.1))\n",
        "    mol9 = np.where(Y_train==(7.9))\n",
        "    mol10 = np.where(Y_train==(8.)) \n",
        "    \n",
        "    val_index = np.hstack([mol1,mol2,mol3,mol4,mol5,\n",
        "                           mol6,mol7,mol8,mol9,mol10])\n",
        "    \n",
        "    val_index = np.squeeze(val_index)\n",
        "\n",
        "    X_1_val = X_1_train[val_index]\n",
        "    X_2_val = X_2_train[val_index]\n",
        "    X_1_train = np.delete(X_1_train, val_index, 0)\n",
        "    X_2_train = np.delete(X_2_train, val_index, 0)\n",
        "\n",
        "    Y_val = Y_train[val_index]\n",
        "    Y_train = np.delete(Y_train, val_index)\n",
        "\n",
        "    \n",
        "    permutation_train = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_train.shape[0])\n",
        "    permutation_test = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_test.shape[0])\n",
        "    permutation_val = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_val.shape[0])\n",
        "\n",
        "    split_train = int(np.around(X_1_train.shape[0]/4,0))\n",
        "    split_val = int(np.around(X_1_val.shape[0]/4,0))\n",
        "    split_test = int(np.around(X_1_test.shape[0]/4,0))\n",
        "\n",
        "    X_1_val =   X_1_val[permutation_val]#[:split_val] \n",
        "    X_2_val =   X_2_val[permutation_val]#[:split_val] \n",
        "    X_1_train = X_1_train[permutation_train]#[:split_train]\n",
        "    X_2_train = X_2_train[permutation_train]#[:split_train]\n",
        "    Y_val =     Y_val[permutation_val]#[:split_val]\n",
        "    Y_train =   Y_train[permutation_train]#[:split_train] \n",
        "    X_1_test =  X_1_test[permutation_test]#[:split_test]\n",
        "    X_2_test =  X_2_test[permutation_test]#[:split_test]\n",
        "    Y_test =    Y_test[permutation_test]#[:split_test]\n",
        "\n",
        "    Y_train = categorical_label(Y_train)\n",
        "    Y_test = categorical_label(Y_test)\n",
        "    Y_val = categorical_label(Y_val)\n",
        "\n",
        "    if augment and aug_iter!=0:\n",
        "      indexes = np.where(Y_train>7.25)\n",
        "      for _ in np.arange(aug_iter):\n",
        "        pass\n",
        "        # new_X = scipy.ndimage.gaussian_filter(X_1_train[indexes],sigma=(1))\n",
        "        # X_1_train = np.concatenate([X_1_train,new_X])\n",
        "\n",
        "        # new_X = scipy.ndimage.gaussian_filter(X_2_train[indexes],sigma=(1))\n",
        "        # X_2_train = np.concatenate([X_2_train,new_X])\n",
        "\n",
        "        # Y_train = np.concatenate([Y_train,Y_train[indexes]])\n",
        "\n",
        "        # new_X = scipy.ndimage.rotate(axes=(1,2),X_1_train[indexes],random.choice([90,180,270]),reshape=False,order=3)\n",
        "        # X_1_train = np.concatenate([X_1_train,new_X])\n",
        "\n",
        "        # new_X = scipy.ndimage.rotate(axes=(1,2),X_2_train[indexes],random.choice([90,180,270]),reshape=False,order=3)\n",
        "        # X_2_train = np.concatenate([X_2_train,new_X])\n",
        "\n",
        "        # Y_train = np.concatenate([Y_train,Y_train[indexes]])\n",
        "\n",
        "    return X_1_train, X_1_test, X_1_val, X_2_train, X_2_test, X_2_val, Y_train, Y_test, Y_val"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "488YbvDuIFkN"
      },
      "source": [
        "#OVER SAMPLING\n",
        "def resampling(x1,x2, y, number):\n",
        "  number = number*1001\n",
        "\n",
        "  hit = np.where(y == 1.0)\n",
        "  miss = np.where(y == 0.0)\n",
        "  print(hit)\n",
        "  print(miss)\n",
        "  X_1_hit = x1[hit]\n",
        "  X_2_hit = x2[hit]\n",
        "  X_1_miss = x1[miss]\n",
        "  X_2_miss = x2[miss]\n",
        "  Y_hit = y[hit]\n",
        "  Y_miss = y[miss]\n",
        "\n",
        "  permutation_hit = np.random.RandomState(seed=42).permutation(X_1_hit.shape[0])\n",
        "  permutation_miss = np.random.RandomState(seed=42).permutation(X_1_miss.shape[0])\n",
        "\n",
        "  X_1_hit = X_1_hit[permutation_hit]\n",
        "  X_2_hit = X_2_hit[permutation_hit]\n",
        "  X_1_miss = X_1_miss[permutation_miss]\n",
        "  X_2_miss = X_2_miss[permutation_miss]\n",
        "  Y_hit = Y_hit[permutation_hit]\n",
        "  Y_miss = Y_miss[permutation_miss]\n",
        "\n",
        "  X_1_copy = X_1_hit[:number].copy()\n",
        "  X_2_copy = X_2_hit[:number].copy()\n",
        "  Y_copy = Y_hit[:number].copy()\n",
        "  X_1_resampled = np.concatenate((X_1_hit, X_1_copy, X_1_miss))\n",
        "  X_2_resampled = np.concatenate((X_2_hit, X_2_copy, X_2_miss))\n",
        "  Y_resampled = np.concatenate((Y_hit, Y_copy, Y_miss))\n",
        "  \n",
        "  return X_1_resampled, X_2_resampled, Y_resampled\n",
        "\n",
        "# X_1_train, X_2_train, Y_train = resampling(X_1_train, X_2_train, Y_train, 6)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDAg1E3JTqxa"
      },
      "source": [
        "def build_CNN(X_1_train):\n",
        "    model = Sequential(name='CNN')\n",
        "\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    inputs = Input(shape=(X_1_train.shape[1], X_1_train.shape[2],X_1_train.shape[3],X_1_train.shape[4]))\n",
        "    model=inputs\n",
        "    model=BatchNormalization()(model)\n",
        "    model = Conv3D(32, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
        "    model = Conv3D(64, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
        "    model = Conv3D(128, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
        "    model = Flatten()(model)\n",
        "    model = Dense(100,activation='relu')(model)\n",
        "    output = model\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxU1ILcJTqxa"
      },
      "source": [
        "def two_headed_network(X_1_train):\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    X_1_CNN = build_CNN(X_1_train)\n",
        "    X_2_CNN = build_CNN(X_1_train)\n",
        "    network = Add()([X_1_CNN.output,X_2_CNN.output])\n",
        "    network = Dense(100,activation='relu')(network)\n",
        "    network = Dense(50,activation='relu')(network)\n",
        "    network = Dense(10,activation='relu')(network)\n",
        "    network = Dense(1,activation = 'sigmoid')(network)\n",
        "    model = Model([X_1_CNN.input, X_2_CNN.input], network)\n",
        "    optimizer = Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "    return model  \n",
        "# CNN = two_headed_network(X_1_train,None)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdo3DyR_BwAo"
      },
      "source": [
        "def train(CNN,X_1_train, X_1_val, X_2_train,\\\n",
        "  X_2_val, Y_train, Y_val):\n",
        "\n",
        "  monitor = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=30,\n",
        "                          verbose=1, \n",
        "                          mode='auto',\n",
        "                          restore_best_weights=True)\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed(42)\n",
        "  CNN.fit([X_1_train, X_2_train],\n",
        "          Y_train,\n",
        "          batch_size=32,\n",
        "          epochs=1000, \n",
        "          validation_data=([X_1_val, X_2_val],\n",
        "                            Y_val),\n",
        "                            callbacks=[monitor],\n",
        "          shuffle=True,\n",
        "          verbose=1)\n",
        "  \n",
        "  model_loss = CNN.evaluate([X_1_val,X_2_val], Y_val, verbose=0)\n",
        "  return model_loss,CNN"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLBgFURvQPzo"
      },
      "source": [
        "def run(itr):\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed(42)\n",
        "  X_1,X_2,Y = pickle.load(open(\"/content/drive/My Drive/Github/resized_first_1000_data_full.p\", \"rb\"))\n",
        "  # X_1,X_2,Y = pickle.load(open(\"/content/drive/My Drive/Github/resized_1_10_data_full.p\", \"rb\"))\n",
        "\n",
        "  Y = np.asarray(Y)\n",
        "  X_1_train, X_1_test, X_1_val, X_2_train, X_2_test,\\\n",
        "  X_2_val, Y_train, Y_test, Y_val = split_shuffle(X_1,X_2,Y,augment=False,aug_iter=itr)\n",
        "  del X_1,X_2,Y\n",
        "  CNN = two_headed_network(X_1_train)\n",
        "  loss,CNN = train(CNN,X_1_train, X_1_val, X_2_train,\\\n",
        "                 X_2_val, Y_train, Y_val)\n",
        "  plt.hist(Y_train)\n",
        "  return loss,CNN"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "z1nkIs8G_NFw",
        "outputId": "e30c453e-7641-40ab-d3eb-028833f65f76"
      },
      "source": [
        "loss,CNN = run(0)\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            " 361/1627 [=====>........................] - ETA: 17s - loss: 0.4798"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6878cd101d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-cd8d948d05a3>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mX_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_headed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2_train\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mX_2_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-53b2ce6f8932>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(CNN, X_1_train, X_1_val, X_2_train, X_2_val, Y_train, Y_val)\u001b[0m\n\u001b[1;32m     17\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           verbose=1)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mmodel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_1_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_2_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxsom0igE3iV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}